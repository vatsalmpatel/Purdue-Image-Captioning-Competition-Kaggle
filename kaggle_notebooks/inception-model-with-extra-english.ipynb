{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from huggingface_hub import notebook_login\nnotebook_login()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-11-20T14:30:34.996425Z","iopub.execute_input":"2022-11-20T14:30:34.996949Z","iopub.status.idle":"2022-11-20T14:30:35.259232Z","shell.execute_reply.started":"2022-11-20T14:30:34.996837Z","shell.execute_reply":"2022-11-20T14:30:35.258292Z"},"trusted":true},"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43a5ee82baa84a189779429d9bfd1804"}},"metadata":{}}]},{"cell_type":"code","source":"! pip install -q datasets tqdm","metadata":{"execution":{"iopub.status.busy":"2022-11-20T14:30:45.141226Z","iopub.execute_input":"2022-11-20T14:30:45.141777Z","iopub.status.idle":"2022-11-20T14:30:55.780115Z","shell.execute_reply.started":"2022-11-20T14:30:45.141731Z","shell.execute_reply":"2022-11-20T14:30:55.778929Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import collections\nimport random\nimport os\nimport time\nimport json\nfrom PIL import Image\nimport io\nimport urllib\nimport uuid\nfrom concurrent.futures import ThreadPoolExecutor\nfrom functools import partial\n\nimport numpy as np\nfrom tqdm import tqdm\nfrom datasets import load_dataset\nfrom datasets.utils.file_utils import get_datasets_user_agent\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom datasets import load_dataset","metadata":{"execution":{"iopub.status.busy":"2022-11-20T14:30:55.782370Z","iopub.execute_input":"2022-11-20T14:30:55.783167Z","iopub.status.idle":"2022-11-20T14:31:00.488541Z","shell.execute_reply.started":"2022-11-20T14:30:55.783122Z","shell.execute_reply":"2022-11-20T14:31:00.487574Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Add the relevant ISO code for the language you want to work with.\niso639_3_letter_code = \"hau\"\n# iso639_3_letter_code = \"tha\"\n# iso639_3_letter_code = \"kir\"\n\n# Download the language specific dataset from HF.\ndataset = load_dataset(\"sil-ai/bloom-captioning\", iso639_3_letter_code, \n                       use_auth_token=True, download_mode='force_redownload')","metadata":{"execution":{"iopub.status.busy":"2022-11-20T14:31:24.341509Z","iopub.execute_input":"2022-11-20T14:31:24.342142Z","iopub.status.idle":"2022-11-20T14:31:34.612458Z","shell.execute_reply.started":"2022-11-20T14:31:24.342105Z","shell.execute_reply":"2022-11-20T14:31:34.611391Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/huggingface_hub/utils/_deprecation.py:97: FutureWarning: Deprecated argument(s) used in 'dataset_info': token. Will not be supported from version '0.12'.\n  warnings.warn(message, FutureWarning)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/41.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7b96b4148bf4f89aa5b983516b8602f"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset bloom_captioning/hau to /root/.cache/huggingface/datasets/sil-ai___bloom_captioning/hau/0.0.0/8efe15718b4a50170c9add75b453aec13ec1c5216111d21815428536fe5913ca...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/176M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ac0da55de5b41a6ae88d0e8385341ec"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset bloom_captioning downloaded and prepared to /root/.cache/huggingface/datasets/sil-ai___bloom_captioning/hau/0.0.0/8efe15718b4a50170c9add75b453aec13ec1c5216111d21815428536fe5913ca. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fad2d499e9614d829444225fb9683314"}},"metadata":{}}]},{"cell_type":"code","source":"# Creating dataframe out of Kyrgyz dataset\nimport pandas as pd\n\ndf_kir_train = pd.DataFrame.from_dict(dataset['train'])\ndf_kir_test = pd.DataFrame.from_dict(dataset['test'])\ndf_kir_val = pd.DataFrame.from_dict(dataset['validation'])","metadata":{"execution":{"iopub.status.busy":"2022-11-20T14:31:34.614531Z","iopub.execute_input":"2022-11-20T14:31:34.614982Z","iopub.status.idle":"2022-11-20T14:31:34.807305Z","shell.execute_reply.started":"2022-11-20T14:31:34.614942Z","shell.execute_reply":"2022-11-20T14:31:34.806419Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"iso639_3_letter_code_eng = \"eng\"\n\n# Download the language specific dataset from HF.\ndataset_eng = load_dataset(\"sil-ai/bloom-captioning\", iso639_3_letter_code_eng, \n                       use_auth_token=True, download_mode='force_redownload')","metadata":{"execution":{"iopub.status.busy":"2022-11-20T14:31:34.808575Z","iopub.execute_input":"2022-11-20T14:31:34.809037Z","iopub.status.idle":"2022-11-20T14:31:46.672477Z","shell.execute_reply.started":"2022-11-20T14:31:34.808984Z","shell.execute_reply":"2022-11-20T14:31:46.671477Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/41.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3dae5c4050374a5084c7860b11f6baf6"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset bloom_captioning/eng to /root/.cache/huggingface/datasets/sil-ai___bloom_captioning/eng/0.0.0/8efe15718b4a50170c9add75b453aec13ec1c5216111d21815428536fe5913ca...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/176M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e4470fb0e4145d8b28d5cae60ef11b1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset bloom_captioning downloaded and prepared to /root/.cache/huggingface/datasets/sil-ai___bloom_captioning/eng/0.0.0/8efe15718b4a50170c9add75b453aec13ec1c5216111d21815428536fe5913ca. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08b6678575a74625a74d9116b2b43f7c"}},"metadata":{}}]},{"cell_type":"code","source":"dataset_eng","metadata":{"execution":{"iopub.status.busy":"2022-11-20T14:31:46.674825Z","iopub.execute_input":"2022-11-20T14:31:46.675533Z","iopub.status.idle":"2022-11-20T14:31:46.684448Z","shell.execute_reply.started":"2022-11-20T14:31:46.675491Z","shell.execute_reply":"2022-11-20T14:31:46.683266Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    test: Dataset({\n        features: ['image_id', 'image_url', 'caption', 'story_id', 'album_id', 'license', 'original_bloom_language_tag', 'index_in_story'],\n        num_rows: 266\n    })\n    validation: Dataset({\n        features: ['image_id', 'image_url', 'caption', 'story_id', 'album_id', 'license', 'original_bloom_language_tag', 'index_in_story'],\n        num_rows: 396\n    })\n    train: Dataset({\n        features: ['image_id', 'image_url', 'caption', 'story_id', 'album_id', 'license', 'original_bloom_language_tag', 'index_in_story'],\n        num_rows: 27956\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"!pip install -q googletrans==3.1.0a0\nimport googletrans\nimport pandas as pd\n\n# Specifying Destination Language\n# lang = 'ky' # For Kyrgyz\nlang = 'ha' # For Hausa\n# lang = 'th' # For Thai\n\nprint(googletrans.LANGUAGES[ lang ])\n\nfrom googletrans import Translator\ntranslator = Translator()","metadata":{"execution":{"iopub.status.busy":"2022-11-20T14:31:55.699952Z","iopub.execute_input":"2022-11-20T14:31:55.700859Z","iopub.status.idle":"2022-11-20T14:32:08.244044Z","shell.execute_reply.started":"2022-11-20T14:31:55.700810Z","shell.execute_reply":"2022-11-20T14:32:08.243034Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbeatrix-jupyterlab 3.1.7 requires google-cloud-bigquery-storage, which is not installed.\npandas-profiling 3.1.0 requires markupsafe~=2.0.1, but you have markupsafe 2.1.1 which is incompatible.\ngoogle-api-core 1.33.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5, but you have protobuf 3.19.4 which is incompatible.\ngcsfs 2022.5.0 requires fsspec==2022.5.0, but you have fsspec 2022.8.2 which is incompatible.\napache-beam 2.40.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.5.1 which is incompatible.\naiobotocore 2.4.0 requires botocore<1.27.60,>=1.27.59, but you have botocore 1.27.93 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mhausa\n","output_type":"stream"}]},{"cell_type":"code","source":"# Creating Pandas dataframe out of the Dataset for translation purposes\ndf_eng_train = pd.DataFrame.from_dict(dataset_eng['train'])\ndf_eng_val = pd.DataFrame.from_dict(dataset_eng['validation'])","metadata":{"execution":{"iopub.status.busy":"2022-11-20T14:45:23.804447Z","iopub.execute_input":"2022-11-20T14:45:23.804833Z","iopub.status.idle":"2022-11-20T14:45:26.762283Z","shell.execute_reply.started":"2022-11-20T14:45:23.804797Z","shell.execute_reply":"2022-11-20T14:45:26.761317Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from multiprocessing import Pool, cpu_count\n\ndef translate_to_lang(data):\n  result = translator.translate(data, dest= lang).text\n  return result\n# For Training data:\nwith Pool(processes= cpu_count() ) as p:\n  ret = p.map(translate_to_lang, [cap for cap in df_eng_train['caption']])\n  df_eng_train['translated_caption'] = ret\n\n# For Validation data:\nwith Pool(processes= cpu_count() ) as p:\n  ret = p.map(translate_to_lang, [cap for cap in df_eng_val['caption']])\n  df_eng_val['translated_caption'] = ret\n\n# This takes around 10 mins to run","metadata":{"execution":{"iopub.status.busy":"2022-11-20T14:45:28.192451Z","iopub.execute_input":"2022-11-20T14:45:28.192811Z","iopub.status.idle":"2022-11-20T15:05:02.231627Z","shell.execute_reply.started":"2022-11-20T14:45:28.192780Z","shell.execute_reply":"2022-11-20T15:05:02.230325Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Testing sample translation\n\nen_cap = df_eng_train['caption'][1]\nky_cap = df_eng_train['translated_caption'][1]\nprint(en_cap)\nprint(ky_cap)","metadata":{"execution":{"iopub.status.busy":"2022-11-20T15:06:23.460678Z","iopub.execute_input":"2022-11-20T15:06:23.461094Z","iopub.status.idle":"2022-11-20T15:06:23.467596Z","shell.execute_reply.started":"2022-11-20T15:06:23.461056Z","shell.execute_reply":"2022-11-20T15:06:23.466558Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"So, Noah’s family had many children. And these children grew up, got married, and had children. People became numerous. Still, they all spoke one same language, the same as Noah.Genesis 11:1\nSaboda haka, iyalin Nuhu suna da ’ya’ya da yawa. Su kuma yaran nan sun girma, sun yi aure, sun haihu. Mutane sun yi yawa. Duk da haka, dukansu suna magana da yare ɗaya, kamar yadda Nuhu ya yi.—Farawa 11:1\n","output_type":"stream"}]},{"cell_type":"code","source":"df_eng_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-11-20T15:06:28.791343Z","iopub.execute_input":"2022-11-20T15:06:28.791720Z","iopub.status.idle":"2022-11-20T15:06:28.813929Z","shell.execute_reply.started":"2022-11-20T15:06:28.791687Z","shell.execute_reply":"2022-11-20T15:06:28.813040Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"                               image_id  \\\n0  3904f355-51f4-416a-ae86-820cd7584533   \n1  65d7b9a0-962d-4314-a6d2-f022712eaac2   \n2  a5ab567e-c3d8-44ea-87c8-88795a7ed429   \n3  51aa825d-3771-4b0c-8905-c2e64542bd2f   \n4  22b17fc0-b92a-4b8f-8f05-2f2fbcf33585   \n\n                                           image_url  \\\n0  https://bloom-vist.s3.amazonaws.com/103%20Babe...   \n1  https://bloom-vist.s3.amazonaws.com/103%20Babe...   \n2  https://bloom-vist.s3.amazonaws.com/103%20Babe...   \n3  https://bloom-vist.s3.amazonaws.com/103%20Babe...   \n4  https://bloom-vist.s3.amazonaws.com/103%20Babe...   \n\n                                             caption  \\\n0  God told them, “Bear many children, so that yo...   \n1  So, Noah’s family had many children. And these...   \n2  People traveled east [toward the sunrise]. The...   \n3  The people said to each other, “We will shape ...   \n4  “We will [must] build a very big city [many st...   \n\n                               story_id                              album_id  \\\n0  6039ef03-b7d1-47aa-b2dc-53817e941461  d5fc6b14-8c63-4d95-a26b-3b7769115b10   \n1  6039ef03-b7d1-47aa-b2dc-53817e941461  d5fc6b14-8c63-4d95-a26b-3b7769115b10   \n2  6039ef03-b7d1-47aa-b2dc-53817e941461  d5fc6b14-8c63-4d95-a26b-3b7769115b10   \n3  6039ef03-b7d1-47aa-b2dc-53817e941461  d5fc6b14-8c63-4d95-a26b-3b7769115b10   \n4  6039ef03-b7d1-47aa-b2dc-53817e941461  d5fc6b14-8c63-4d95-a26b-3b7769115b10   \n\n    license original_bloom_language_tag  index_in_story  \\\n0  cc-by-sa                          en               0   \n1  cc-by-sa                          en               1   \n2  cc-by-sa                          en               2   \n3  cc-by-sa                          en               3   \n4  cc-by-sa                          en               4   \n\n                                  translated_caption  \n0  Allah ya ce musu, “Ku haifi ’ya’ya da yawa, do...  \n1  Saboda haka, iyalin Nuhu suna da ’ya’ya da yaw...  \n2  Mutane sun yi tafiya gabas [zuwa fitowar rana]...  \n3  Jama'a suka ce wa juna, “Za mu yi tubalin laka...  \n4  \"Dole ne mu gina wani babban birni [gidaje mas...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_id</th>\n      <th>image_url</th>\n      <th>caption</th>\n      <th>story_id</th>\n      <th>album_id</th>\n      <th>license</th>\n      <th>original_bloom_language_tag</th>\n      <th>index_in_story</th>\n      <th>translated_caption</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3904f355-51f4-416a-ae86-820cd7584533</td>\n      <td>https://bloom-vist.s3.amazonaws.com/103%20Babe...</td>\n      <td>God told them, “Bear many children, so that yo...</td>\n      <td>6039ef03-b7d1-47aa-b2dc-53817e941461</td>\n      <td>d5fc6b14-8c63-4d95-a26b-3b7769115b10</td>\n      <td>cc-by-sa</td>\n      <td>en</td>\n      <td>0</td>\n      <td>Allah ya ce musu, “Ku haifi ’ya’ya da yawa, do...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>65d7b9a0-962d-4314-a6d2-f022712eaac2</td>\n      <td>https://bloom-vist.s3.amazonaws.com/103%20Babe...</td>\n      <td>So, Noah’s family had many children. And these...</td>\n      <td>6039ef03-b7d1-47aa-b2dc-53817e941461</td>\n      <td>d5fc6b14-8c63-4d95-a26b-3b7769115b10</td>\n      <td>cc-by-sa</td>\n      <td>en</td>\n      <td>1</td>\n      <td>Saboda haka, iyalin Nuhu suna da ’ya’ya da yaw...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>a5ab567e-c3d8-44ea-87c8-88795a7ed429</td>\n      <td>https://bloom-vist.s3.amazonaws.com/103%20Babe...</td>\n      <td>People traveled east [toward the sunrise]. The...</td>\n      <td>6039ef03-b7d1-47aa-b2dc-53817e941461</td>\n      <td>d5fc6b14-8c63-4d95-a26b-3b7769115b10</td>\n      <td>cc-by-sa</td>\n      <td>en</td>\n      <td>2</td>\n      <td>Mutane sun yi tafiya gabas [zuwa fitowar rana]...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>51aa825d-3771-4b0c-8905-c2e64542bd2f</td>\n      <td>https://bloom-vist.s3.amazonaws.com/103%20Babe...</td>\n      <td>The people said to each other, “We will shape ...</td>\n      <td>6039ef03-b7d1-47aa-b2dc-53817e941461</td>\n      <td>d5fc6b14-8c63-4d95-a26b-3b7769115b10</td>\n      <td>cc-by-sa</td>\n      <td>en</td>\n      <td>3</td>\n      <td>Jama'a suka ce wa juna, “Za mu yi tubalin laka...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>22b17fc0-b92a-4b8f-8f05-2f2fbcf33585</td>\n      <td>https://bloom-vist.s3.amazonaws.com/103%20Babe...</td>\n      <td>“We will [must] build a very big city [many st...</td>\n      <td>6039ef03-b7d1-47aa-b2dc-53817e941461</td>\n      <td>d5fc6b14-8c63-4d95-a26b-3b7769115b10</td>\n      <td>cc-by-sa</td>\n      <td>en</td>\n      <td>4</td>\n      <td>\"Dole ne mu gina wani babban birni [gidaje mas...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"col_arrng = ['image_id', 'image_url', 'caption', 'story_id', 'album_id', 'license','original_bloom_language_tag', 'index_in_story']\n\n# For Traning Data\ndf_engtokir_train = df_eng_train.drop(['caption'], axis=1)\ndf_engtokir_train = df_engtokir_train.rename(columns={'translated_caption':'caption'})\ndf_engtokir_train['original_bloom_language_tag'] = lang\ndf_engtokir_train = df_engtokir_train[col_arrng]\n\n# For Validation Data\ndf_engtokir_val = df_eng_val.drop(['caption'], axis=1)\ndf_engtokir_val = df_engtokir_val.rename(columns={'translated_caption':'caption'})\ndf_engtokir_val['original_bloom_language_tag'] = lang\ndf_engtokir_val = df_engtokir_val[col_arrng]\n\n# Merging Traing Data\nmerge_df_train = pd.concat([df_kir_train, df_engtokir_train], axis=0)\nprint(merge_df_train.shape)\n\n# Merging Validation Data\nmerge_df_val = pd.concat([df_kir_val, df_engtokir_val], axis=0)\nprint(merge_df_val.shape)","metadata":{"execution":{"iopub.status.busy":"2022-11-20T15:06:38.270101Z","iopub.execute_input":"2022-11-20T15:06:38.270466Z","iopub.status.idle":"2022-11-20T15:06:38.322641Z","shell.execute_reply.started":"2022-11-20T15:06:38.270435Z","shell.execute_reply":"2022-11-20T15:06:38.321449Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"(29717, 8)\n(448, 8)\n","output_type":"stream"}]},{"cell_type":"code","source":"merge_df_val.head()","metadata":{"execution":{"iopub.status.busy":"2022-11-20T15:06:40.586519Z","iopub.execute_input":"2022-11-20T15:06:40.587463Z","iopub.status.idle":"2022-11-20T15:06:40.601402Z","shell.execute_reply.started":"2022-11-20T15:06:40.587416Z","shell.execute_reply":"2022-11-20T15:06:40.600407Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"                               image_id  \\\n0  e99df6f8-0b17-45e6-b01a-a69539e7b3ec   \n1  6c70f73d-0758-4b55-a755-bbe977097fa0   \n2  6b689bfd-9e00-40ec-aa74-6a7c09d39c3a   \n3  47d00f35-50b3-4b19-ad73-90da313111fa   \n4  a28a2eeb-3f43-461c-8de7-bcd2afe5dc43   \n\n                                           image_url  \\\n0  https://bloom-vist.s3.amazonaws.com/%E0%A4%AF%...   \n1  https://bloom-vist.s3.amazonaws.com/%E0%A4%AF%...   \n2  https://bloom-vist.s3.amazonaws.com/%E0%A4%AF%...   \n3  https://bloom-vist.s3.amazonaws.com/%E0%A4%AF%...   \n4  https://bloom-vist.s3.amazonaws.com/%E0%A4%AF%...   \n\n                                             caption  \\\n0  Bayan kwana biyu sun wuce, Yesu ya cewa almaji...   \n1  Almajiran Yesu suka amsa suka ce, “Malam, in L...   \n2  Da Yesu ya iso garin Li’azaru, Li’azaru ya yi ...   \n3  Yesu ya amsa ya ce, “Ni ne tashin mattatu da k...   \n4  Sai Maryamu ta zo. Ta faɗi a ƙafafuwan Yesu ta...   \n\n                               story_id                              album_id  \\\n0  9e8e9650-9e2a-40c1-ad8a-9b484514df67  72d66eb6-d88a-47ab-a8cb-80932918d88e   \n1  9e8e9650-9e2a-40c1-ad8a-9b484514df67  72d66eb6-d88a-47ab-a8cb-80932918d88e   \n2  9e8e9650-9e2a-40c1-ad8a-9b484514df67  72d66eb6-d88a-47ab-a8cb-80932918d88e   \n3  9e8e9650-9e2a-40c1-ad8a-9b484514df67  72d66eb6-d88a-47ab-a8cb-80932918d88e   \n4  9e8e9650-9e2a-40c1-ad8a-9b484514df67  72d66eb6-d88a-47ab-a8cb-80932918d88e   \n\n    license original_bloom_language_tag  index_in_story  \n0  cc-by-nc                          ha               0  \n1  cc-by-nc                          ha               1  \n2  cc-by-nc                          ha               2  \n3  cc-by-nc                          ha               3  \n4  cc-by-nc                          ha               4  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_id</th>\n      <th>image_url</th>\n      <th>caption</th>\n      <th>story_id</th>\n      <th>album_id</th>\n      <th>license</th>\n      <th>original_bloom_language_tag</th>\n      <th>index_in_story</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>e99df6f8-0b17-45e6-b01a-a69539e7b3ec</td>\n      <td>https://bloom-vist.s3.amazonaws.com/%E0%A4%AF%...</td>\n      <td>Bayan kwana biyu sun wuce, Yesu ya cewa almaji...</td>\n      <td>9e8e9650-9e2a-40c1-ad8a-9b484514df67</td>\n      <td>72d66eb6-d88a-47ab-a8cb-80932918d88e</td>\n      <td>cc-by-nc</td>\n      <td>ha</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>6c70f73d-0758-4b55-a755-bbe977097fa0</td>\n      <td>https://bloom-vist.s3.amazonaws.com/%E0%A4%AF%...</td>\n      <td>Almajiran Yesu suka amsa suka ce, “Malam, in L...</td>\n      <td>9e8e9650-9e2a-40c1-ad8a-9b484514df67</td>\n      <td>72d66eb6-d88a-47ab-a8cb-80932918d88e</td>\n      <td>cc-by-nc</td>\n      <td>ha</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6b689bfd-9e00-40ec-aa74-6a7c09d39c3a</td>\n      <td>https://bloom-vist.s3.amazonaws.com/%E0%A4%AF%...</td>\n      <td>Da Yesu ya iso garin Li’azaru, Li’azaru ya yi ...</td>\n      <td>9e8e9650-9e2a-40c1-ad8a-9b484514df67</td>\n      <td>72d66eb6-d88a-47ab-a8cb-80932918d88e</td>\n      <td>cc-by-nc</td>\n      <td>ha</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>47d00f35-50b3-4b19-ad73-90da313111fa</td>\n      <td>https://bloom-vist.s3.amazonaws.com/%E0%A4%AF%...</td>\n      <td>Yesu ya amsa ya ce, “Ni ne tashin mattatu da k...</td>\n      <td>9e8e9650-9e2a-40c1-ad8a-9b484514df67</td>\n      <td>72d66eb6-d88a-47ab-a8cb-80932918d88e</td>\n      <td>cc-by-nc</td>\n      <td>ha</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>a28a2eeb-3f43-461c-8de7-bcd2afe5dc43</td>\n      <td>https://bloom-vist.s3.amazonaws.com/%E0%A4%AF%...</td>\n      <td>Sai Maryamu ta zo. Ta faɗi a ƙafafuwan Yesu ta...</td>\n      <td>9e8e9650-9e2a-40c1-ad8a-9b484514df67</td>\n      <td>72d66eb6-d88a-47ab-a8cb-80932918d88e</td>\n      <td>cc-by-nc</td>\n      <td>ha</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from datasets import Dataset, DatasetDict\ntraindf = Dataset.from_pandas(merge_df_train)\ntestdf = Dataset.from_pandas(df_kir_test)\nvaldf = Dataset.from_pandas(merge_df_val)\n\ndf = DatasetDict()\n\ndf['test'] = testdf\ndf['validation'] = valdf\ndf['train'] = traindf","metadata":{"execution":{"iopub.status.busy":"2022-11-20T15:06:46.319612Z","iopub.execute_input":"2022-11-20T15:06:46.319983Z","iopub.status.idle":"2022-11-20T15:06:46.372108Z","shell.execute_reply.started":"2022-11-20T15:06:46.319942Z","shell.execute_reply":"2022-11-20T15:06:46.371184Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"dataset = df\ndataset","metadata":{"execution":{"iopub.status.busy":"2022-11-20T15:07:30.505570Z","iopub.execute_input":"2022-11-20T15:07:30.505933Z","iopub.status.idle":"2022-11-20T15:07:30.512923Z","shell.execute_reply.started":"2022-11-20T15:07:30.505899Z","shell.execute_reply":"2022-11-20T15:07:30.511818Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    test: Dataset({\n        features: ['image_id', 'image_url', 'caption', 'story_id', 'album_id', 'license', 'original_bloom_language_tag', 'index_in_story'],\n        num_rows: 52\n    })\n    validation: Dataset({\n        features: ['image_id', 'image_url', 'caption', 'story_id', 'album_id', 'license', 'original_bloom_language_tag', 'index_in_story', '__index_level_0__'],\n        num_rows: 448\n    })\n    train: Dataset({\n        features: ['image_id', 'image_url', 'caption', 'story_id', 'album_id', 'license', 'original_bloom_language_tag', 'index_in_story', '__index_level_0__'],\n        num_rows: 29717\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"! rm -rf images\n! mkdir images\n\nUSER_AGENT = get_datasets_user_agent()\n\ndef fetch_single_image(image_url, timeout=None, retries=0):\n    request = urllib.request.Request(\n        image_url,\n        data=None,\n        headers={\"user-agent\": USER_AGENT},\n    )\n    with urllib.request.urlopen(request, timeout=timeout) as req:\n        if 'png' in image_url:\n          png = Image.open(io.BytesIO(req.read())).convert('RGBA')\n          png.load() # required for png.split()\n          background = Image.new(\"RGB\", png.size, (255, 255, 255))\n          background.paste(png, mask=png.split()[3]) # 3 is the alpha channel\n          image_id = str(uuid.uuid4())\n          image_path = \"images/\" + image_id + \".jpg\"\n          background.save(image_path, 'JPEG', quality=80)\n        else:\n          image = Image.open(io.BytesIO(req.read()))\n          image_id = str(uuid.uuid4())\n          image_path = \"images/\" + image_id + \".jpg\"\n          image.save(image_path)\n    return image_path\n\ndef fetch_images(batch, num_threads, timeout=None, retries=3):\n    fetch_single_image_with_args = partial(fetch_single_image, timeout=timeout, retries=retries)\n    with ThreadPoolExecutor(max_workers=num_threads) as executor:\n        batch[\"image_path\"] = list(executor.map(fetch_single_image_with_args, batch[\"image_url\"]))\n    return batch\n\nnum_threads = 20\ndataset = dataset.map(fetch_images, batched=True, batch_size=2000, fn_kwargs={\"num_threads\": num_threads})","metadata":{"execution":{"iopub.status.busy":"2022-11-20T16:04:40.183810Z","iopub.execute_input":"2022-11-20T16:04:40.184208Z","iopub.status.idle":"2022-11-20T16:11:41.278939Z","shell.execute_reply.started":"2022-11-20T16:04:40.184174Z","shell.execute_reply":"2022-11-20T16:11:41.277189Z"},"trusted":true},"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed0ad99e85dd48a29073301f68554213"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4034288d77e4d5399b159261f503b1e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/15 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21aa58c208b5420a805d83a8d5edf1a8"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_24/792312297.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mnum_threads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatched\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"num_threads\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnum_threads\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/datasets/dataset_dict.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_names, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, desc)\u001b[0m\n\u001b[1;32m    456\u001b[0m                     \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m                 )\n\u001b[0;32m--> 458\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m             }\n\u001b[1;32m    460\u001b[0m         )\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/datasets/dataset_dict.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    456\u001b[0m                     \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m                 )\n\u001b[0;32m--> 458\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m             }\n\u001b[1;32m    460\u001b[0m         )\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   1971\u001b[0m                 \u001b[0mnew_fingerprint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_fingerprint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1972\u001b[0m                 \u001b[0mdisable_tqdm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisable_tqdm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1973\u001b[0;31m                 \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1974\u001b[0m             )\n\u001b[1;32m   1975\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Dataset\"\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"self\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0;31m# apply actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DatasetDict\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    485\u001b[0m         }\n\u001b[1;32m    486\u001b[0m         \u001b[0;31m# apply actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DatasetDict\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         \u001b[0;31m# re-apply format to the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/datasets/fingerprint.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0;31m# Call actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m             \u001b[0;31m# Update fingerprint of in-place transforms + update in-place history of transforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m_map_single\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset, disable_tqdm, desc, cache_only)\u001b[0m\n\u001b[1;32m   2341\u001b[0m                                 \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2342\u001b[0m                                 \u001b[0mcheck_same_num_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_indexes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2343\u001b[0;31m                                 \u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2344\u001b[0m                             )\n\u001b[1;32m   2345\u001b[0m                         \u001b[0;32mexcept\u001b[0m \u001b[0mNumExamplesMismatchError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mapply_function_on_filtered_inputs\u001b[0;34m(inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[1;32m   2218\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwith_rank\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2219\u001b[0m                 \u001b[0madditional_args\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2220\u001b[0;31m             \u001b[0mprocessed_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfn_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0madditional_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2221\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mupdate_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2222\u001b[0m                 \u001b[0;31m# Check if the function returns updated examples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mdecorated\u001b[0;34m(item, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1913\u001b[0m                 )\n\u001b[1;32m   1914\u001b[0m                 \u001b[0;31m# Use the LazyDict internally, while mapping the function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1915\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecorated_item\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1916\u001b[0m                 \u001b[0;31m# Return a standard dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLazyDict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_24/792312297.py\u001b[0m in \u001b[0;36mfetch_images\u001b[0;34m(batch, num_threads, timeout, retries)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mfetch_single_image_with_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch_single_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mThreadPoolExecutor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_threads\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"image_path\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch_single_image_with_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"image_url\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    596\u001b[0m                     \u001b[0;31m# Careful not to keep a reference to the popped future\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m                         \u001b[0;32myield\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"image_model = tf.keras.applications.InceptionV3(include_top=False, weights='imagenet')\nnew_input = image_model.input\nhidden_layer = image_model.layers[-1].output\n\nimage_features_extract_model = tf.keras.Model(new_input, hidden_layer)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_image(image_path):\n    img = tf.io.read_file(image_path)\n    img = tf.io.decode_jpeg(img, channels=3)\n    img = tf.keras.layers.Resizing(299, 299)(img)\n    img = tf.keras.applications.inception_v3.preprocess_input(img)\n    return img, image_path","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get unique train images\nencode_train = sorted(set(dataset['train']['image_path']))\n\n# Feel free to change batch_size according to your system configuration\nimage_dataset = tf.data.Dataset.from_tensor_slices(encode_train)\nimage_dataset = image_dataset.map(load_image, num_parallel_calls=tf.data.AUTOTUNE).batch(16)\n\nfor img, path in tqdm(image_dataset):\n  batch_features = image_features_extract_model(img)\n  batch_features = tf.reshape(batch_features,\n                              (batch_features.shape[0], -1, batch_features.shape[3]))\n\n  for bf, p in zip(batch_features, path):\n    path_of_feature = p.numpy().decode(\"utf-8\")\n    np.save(path_of_feature, bf.numpy())\n\n# Get unique test images\nencode_test = sorted(set(dataset['test']['image_path']))\n\n# Feel free to change batch_size according to your system configuration\nimage_dataset_test = tf.data.Dataset.from_tensor_slices(encode_test)\nimage_dataset_test = image_dataset_test.map(load_image, num_parallel_calls=tf.data.AUTOTUNE).batch(16)\n\nfor img, path in tqdm(image_dataset_test):\n  batch_features = image_features_extract_model(img)\n  batch_features = tf.reshape(batch_features,\n                              (batch_features.shape[0], -1, batch_features.shape[3]))\n\n  for bf, p in zip(batch_features, path):\n    path_of_feature = p.numpy().decode(\"utf-8\")\n    np.save(path_of_feature, bf.numpy())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Add some special tokens and clean up new line characters.\ntrain_captions = [f\"<start> {x} <end>\" for x in dataset['train']['caption']]\ntrain_captions = [x.replace('\\n', ' ') for x in train_captions]\ntest_captions = [f\"<start> {x} <end>\" for x in dataset['test']['caption']]\ntest_captions = [x.replace('\\n', ' ') for x in test_captions]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"caption_dataset = tf.data.Dataset.from_tensor_slices(train_captions)\n\n# We will override the default standardization of TextVectorization to preserve\n# \"<>\" characters, so we preserve the tokens for the <start> and <end>.\ndef standardize(inputs):\n  inputs = tf.strings.lower(inputs)\n  return tf.strings.regex_replace(inputs,\n                                  r\"!\\\"#$%&\\(\\)\\*\\+.,-/:;=?@\\[\\\\\\]^_`{|}~\", \"\")\n\n# Max word count for a caption.\nmax_length = 25\n# Use the top 5000 words for a vocabulary.\nvocabulary_size = 5000\ntokenizer = tf.keras.layers.TextVectorization(\n    max_tokens=vocabulary_size,\n    standardize=standardize,\n    output_sequence_length=max_length)\n# Learn the vocabulary from the caption data.\ntokenizer.adapt(caption_dataset)\n\n# Create the tokenized vectors\ncap_vector = caption_dataset.map(lambda x: tokenizer(x))\n\n# Create mappings for words to indices and indicies to words.\nword_to_index = tf.keras.layers.StringLookup(\n    mask_token=\"\",\n    vocabulary=tokenizer.get_vocabulary())\nindex_to_word = tf.keras.layers.StringLookup(\n    mask_token=\"\",\n    vocabulary=tokenizer.get_vocabulary(),\n    invert=True)\n\ncaption_dataset_test = tf.data.Dataset.from_tensor_slices(test_captions)\ncap_vector_test = caption_dataset_test.map(lambda x: tokenizer(x))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create some mas between images, vectors, and captions\nimg_to_cap_vector = collections.defaultdict(list)\nfor img, cap in zip(dataset['train']['image_path'], cap_vector):\n  img_to_cap_vector[img].append(cap)\n\nimg_name_train = []\ncap_train = []\nfor imgt in list(img_to_cap_vector.keys()):\n  capt_len = len(img_to_cap_vector[imgt])\n  img_name_train.extend([imgt] * capt_len)\n  cap_train.extend(img_to_cap_vector[imgt])\n\nimg_to_cap_vector_test = collections.defaultdict(list)\nfor img, cap in zip(dataset['test']['image_path'], cap_vector_test):\n  img_to_cap_vector_test[img].append(cap)\n\nimg_name_test = []\ncap_test = []\nfor imgv in list(img_to_cap_vector_test.keys()):\n  capv_len = len(img_to_cap_vector_test[imgv])\n  img_name_test.extend([imgv] * capv_len)\n  cap_test.extend(img_to_cap_vector_test[imgv])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Feel free to change these parameters according to your system's configuration\nBATCH_SIZE = 64\nBUFFER_SIZE = 1000\nembedding_dim = 1024\nunits = 512\nnum_steps = len(img_name_train) // BATCH_SIZE\n\n# Shape of the vector extracted from InceptionV3 is (64, 2048)\n# These two variables represent that vector shape\nfeatures_shape = 2048\nattention_features_shape = 64","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the numpy files\ndef map_func(img_name, cap):\n  img_tensor = np.load(img_name.decode('utf-8')+'.npy')\n  return img_tensor, cap","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_tf = tf.data.Dataset.from_tensor_slices((img_name_train, cap_train))\n\n# Use map to load the numpy files in parallel\ndataset_tf = dataset_tf.map(lambda item1, item2: tf.numpy_function(\n          map_func, [item1, item2], [tf.float32, tf.int64]),\n          num_parallel_calls=tf.data.AUTOTUNE)\n\n# Shuffle and batch\ndataset_tf = dataset_tf.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\ndataset_tf = dataset_tf.prefetch(buffer_size=tf.data.AUTOTUNE)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BahdanauAttention(tf.keras.Model):\n  def __init__(self, units):\n    super(BahdanauAttention, self).__init__()\n    self.W1 = tf.keras.layers.Dense(units)\n    self.W2 = tf.keras.layers.Dense(units)\n    self.V = tf.keras.layers.Dense(1)\n\n  def call(self, features, hidden):\n    # features(CNN_encoder output) shape == (batch_size, 64, embedding_dim)\n\n    # hidden shape == (batch_size, hidden_size)\n    # hidden_with_time_axis shape == (batch_size, 1, hidden_size)\n    hidden_with_time_axis = tf.expand_dims(hidden, 1)\n\n    # attention_hidden_layer shape == (batch_size, 64, units)\n    attention_hidden_layer = (tf.nn.tanh(self.W1(features) +\n                                         self.W2(hidden_with_time_axis)))\n\n    # score shape == (batch_size, 64, 1)\n    # This gives you an unnormalized score for each image feature.\n    score = self.V(attention_hidden_layer)\n\n    # attention_weights shape == (batch_size, 64, 1)\n    attention_weights = tf.nn.softmax(score, axis=1)\n\n    # context_vector shape after sum == (batch_size, hidden_size)\n    context_vector = attention_weights * features\n    context_vector = tf.reduce_sum(context_vector, axis=1)\n\n    return context_vector, attention_weights\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CNN_Encoder(tf.keras.Model):\n    # Since you have already extracted the features and dumped it\n    # This encoder passes those features through a Fully connected layer\n    def __init__(self, embedding_dim):\n        super(CNN_Encoder, self).__init__()\n        # shape after fc == (batch_size, 64, embedding_dim)\n        self.fc = tf.keras.layers.Dense(embedding_dim)\n\n    def call(self, x):\n        x = self.fc(x)\n        x = tf.nn.relu(x)\n        return x","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RNN_Decoder(tf.keras.Model):\n  def __init__(self, embedding_dim, units, vocab_size):\n    super(RNN_Decoder, self).__init__()\n    self.units = units\n\n    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n    self.gru = tf.keras.layers.GRU(self.units,\n                                   return_sequences=True,\n                                   return_state=True,\n                                   recurrent_initializer='glorot_uniform')\n    self.fc1 = tf.keras.layers.Dense(self.units)\n    self.fc2 = tf.keras.layers.Dense(vocab_size)\n\n    self.attention = BahdanauAttention(self.units)\n\n  def call(self, x, features, hidden):\n    # defining attention as a separate model\n    context_vector, attention_weights = self.attention(features, hidden)\n\n    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n    x = self.embedding(x)\n\n    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n\n    # passing the concatenated vector to the GRU\n    output, state = self.gru(x)\n\n    # shape == (batch_size, max_length, hidden_size)\n    x = self.fc1(output)\n\n    # x shape == (batch_size * max_length, hidden_size)\n    x = tf.reshape(x, (-1, x.shape[2]))\n\n    # output shape == (batch_size * max_length, vocab)\n    x = self.fc2(x)\n\n    return x, state, attention_weights\n\n  def reset_state(self, batch_size):\n    return tf.zeros((batch_size, self.units))\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize the encoder and decoder\nencoder = CNN_Encoder(embedding_dim)\ndecoder = RNN_Decoder(embedding_dim, units, tokenizer.vocabulary_size())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training config.\noptimizer = tf.keras.optimizers.Adam()\nloss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n    from_logits=True, reduction='none')\n\n# Loss function to use during training.\ndef loss_function(real, pred):\n  mask = tf.math.logical_not(tf.math.equal(real, 0))\n  loss_ = loss_object(real, pred)\n\n  mask = tf.cast(mask, dtype=loss_.dtype)\n  loss_ *= mask\n\n  return tf.reduce_mean(loss_)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make sure we save checkpoints during training\ncheckpoint_path = \"./checkpoints/new-kir/train\"\nckpt = tf.train.Checkpoint(encoder=encoder,\n                           decoder=decoder,\n                           optimizer=optimizer)\nckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start_epoch = 0\nif ckpt_manager.latest_checkpoint:\n  start_epoch = int(ckpt_manager.latest_checkpoint.split('-')[-1])\n  \n  # restoring the latest checkpoint in checkpoint_path\n  ckpt.restore(ckpt_manager.latest_checkpoint)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# adding this in a separate cell because if you run the training cell\n# many times, the loss_plot array will be reset\nloss_plot = []","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@tf.function\ndef train_step(img_tensor, target):\n  loss = 0\n\n  # initializing the hidden state for each batch\n  # because the captions are not related from image to image\n  hidden = decoder.reset_state(batch_size=target.shape[0])\n\n  dec_input = tf.expand_dims([word_to_index(tf.constant('<start>'))] * target.shape[0], 1)\n\n  with tf.GradientTape() as tape:\n      features = encoder(img_tensor)\n\n      for i in range(1, target.shape[1]):\n          # passing the features through the decoder\n          predictions, hidden, _ = decoder(dec_input, features, hidden)\n\n          loss += loss_function(target[:, i], predictions)\n\n          # using teacher forcing\n          dec_input = tf.expand_dims(target[:, i], 1)\n\n  total_loss = (loss / int(target.shape[1]))\n  trainable_variables = encoder.trainable_variables + decoder.trainable_variables\n  gradients = tape.gradient(loss, trainable_variables)\n  optimizer.apply_gradients(zip(gradients, trainable_variables))\n\n  return loss, total_loss","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Adjust this depending on how long you want to train\nEPOCHS = 25\n\n# Train our model!\nfor epoch in range(start_epoch, EPOCHS):\n    start = time.time()\n    total_loss = 0\n\n    for (batch, (img_tensor, target)) in enumerate(dataset_tf):\n        batch_loss, t_loss = train_step(img_tensor, target)\n        total_loss += t_loss\n\n        if batch % 100 == 0:\n            average_batch_loss = batch_loss.numpy()/int(target.shape[1])\n            print(f'Epoch {epoch+1} Batch {batch} Loss {average_batch_loss:.4f}')\n    # storing the epoch end loss value to plot later\n    loss_plot.append(total_loss / num_steps)\n\n    if epoch % 5 == 0:\n      ckpt_manager.save()\n\n    print(f'Epoch {epoch+1} Loss {total_loss/num_steps:.6f}')\n    print(f'Time taken for 1 epoch {time.time()-start:.2f} sec\\n')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(loss_plot)\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('Loss Plot')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predictions - Vatsal\n","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}